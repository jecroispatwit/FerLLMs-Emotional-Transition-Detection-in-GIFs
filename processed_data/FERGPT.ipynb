{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cv in /home/jecroisp/.local/lib/python3.12/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv\n",
    "import imageio\n",
    "import torch\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion classes\n",
    "emotion_labels = [\"Anger\", \"Disgust\", \"Fear\", \"Happiness\", \"Neutral\", \"Sadness\"]\n",
    "\n",
    "# Initialize a pre-trained Vision Transformer model\n",
    "class EmotionRecognitionViT(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(EmotionRecognitionViT, self).__init__()\n",
    "        # Load the pre-trained Vision Transformer\n",
    "        self.vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Replace the classifier head with one suitable for our task\n",
    "        in_features = self.vit.heads[0].in_features  # Access the input features of the last layer\n",
    "        self.vit.heads = nn.Sequential(nn.Linear(in_features, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "# Initialize the ViT model\n",
    "model = EmotionRecognitionViT(num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_236180/449562827.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/jecroisp/Thesis/FerLLMs-Emotional-Transition-Detection-in-GIFs/p_crema/emotion_recognition_vit.pth\"\n",
    "model = EmotionRecognitionViT(num_classes=6)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Transforms for frames\n",
    "frame_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gif_as_tensor(gif_path):\n",
    "    \"\"\"\n",
    "    Loads all frames from a GIF, applies frame_transforms, \n",
    "    and returns a stacked tensor of shape (num_frames, 3, 224, 224).\n",
    "    \"\"\"\n",
    "    gif_frames = imageio.mimread(gif_path)\n",
    "    processed_frames = []\n",
    "    for frame in gif_frames:\n",
    "        pil_img = Image.fromarray(frame).convert(\"RGB\")\n",
    "        processed_frames.append(frame_transforms(pil_img))\n",
    "    if len(processed_frames) == 0:\n",
    "        return None\n",
    "    return torch.stack(processed_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotions_for_gif(model, gif_tensor):\n",
    "    \"\"\"\n",
    "    Given a stacked tensor of GIF frames, compute the average \n",
    "    softmax probability across frames and return a dict with scores.\n",
    "    \"\"\"\n",
    "    if gif_tensor is None:\n",
    "        return None\n",
    "\n",
    "    gif_tensor = gif_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(gif_tensor)\n",
    "        probs = F.softmax(outputs, dim=1)  # shape: (num_frames, 6)\n",
    "        avg_probs = probs.mean(dim=0).cpu().numpy()  # shape: (6,)\n",
    "    \n",
    "    predicted_idx = np.argmax(avg_probs)\n",
    "    predicted_label = emotion_labels[predicted_idx]\n",
    "    predicted_confidence = avg_probs[predicted_idx]\n",
    "    \n",
    "    # Construct a dictionary of all scores\n",
    "    scores_dict = {\n",
    "        \"Predicted_Emotion\": predicted_label,\n",
    "        \"Anger_Score\": float(avg_probs[0]),\n",
    "        \"Disgust_Score\": float(avg_probs[1]),\n",
    "        \"Fear_Score\": float(avg_probs[2]),\n",
    "        \"Happiness_Score\": float(avg_probs[3]),\n",
    "        \"Neutral_Score\": float(avg_probs[4]),\n",
    "        \"Sadness_Score\": float(avg_probs[5]),\n",
    "        \"Max_Confidence\": float(predicted_confidence)\n",
    "    }\n",
    "    return scores_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Prompt_Label                                        Prompt_Text\n",
      "0     Prompt 1  Describe the emotional transition in the given...\n",
      "1     Prompt 2  Using only the variations in the confidence sc...\n",
      "2     Prompt 3  Based solely on the model’s confidence score f...\n",
      "3     Prompt 4  Analyze the temporal trends in the emotion con...\n",
      "4     Prompt 5  Interpret the progression of emotion in the sc...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of prompt strings\n",
    "prompts = [\n",
    "    \"Describe the emotional transition in the given scene with clarity, focusing solely on inferences drawn from the model's confidence scores. Interpret subtle differences between scores to determine when and how the subject's emotion shifts, using specific language (e.g., 'subject transitions from excitement to sadness') without mentioning direct numerical values or static labels. Keep the description concise (under 15 words) and ensure it captures the temporal progression of the scene.\",\n",
    "    \"Using only the variations in the confidence scores provided, succinctly articulate the subject's emotional shift over time. Capture the change from one dominant emotion to another using precise, dynamic verbs (e.g., 'morphs from surprise to calm') without quoting numbers. Limit your response to under 15 words.\",\n",
    "    \"Based solely on the model’s confidence score fluctuations, craft a brief narrative describing how the subject’s emotion evolves throughout the scene. Use specific phrases (e.g., 'switches from joy to apprehension') and avoid direct numerical references, keeping your description under 15 words.\",\n",
    "    \"Analyze the temporal trends in the emotion confidence scores to derive a succinct, natural language depiction of the subject's emotional transition. Employ clear descriptors (e.g., 'changes from elation to concern') without referencing exact figures, and keep it under 15 words.\",\n",
    "    \"Interpret the progression of emotion in the scene exclusively from the provided confidence scores. Deliver a concise (under 15 words) depiction of the shift using specific language (e.g., 'evolves from optimism to melancholy'), avoiding any direct numerical or static label mentions.\"\n",
    "]\n",
    "\n",
    "# Create a separate DataFrame for each prompt with a simple label\n",
    "prompt_dfs = {}\n",
    "for idx, prompt in enumerate(prompts, start=1):\n",
    "    df = pd.DataFrame({\n",
    "        \"Prompt_Label\": [f\"Prompt {idx}\"],\n",
    "        \"Prompt_Text\": [prompt]\n",
    "    })\n",
    "    prompt_dfs[f\"Prompt_{idx}\"] = df\n",
    "\n",
    "# Optionally, combine all individual DataFrames into one master DataFrame\n",
    "master_df = pd.concat(prompt_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Display the master DataFrame\n",
    "print(master_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption_from_scores(emotion_scores, prompt_text):\n",
    "    \"\"\"\n",
    "    Prompt GPT-3.5 to generate a concise caption describing the emotional transition.\n",
    "    \n",
    "    Parameters:\n",
    "      emotion_scores (dict): Dictionary containing emotion scores.\n",
    "      prompt_text (str): The variable prompt text (one of your 5 prompts).\n",
    "      \n",
    "    Returns:\n",
    "      str: GPT-3.5 generated caption.\n",
    "    \"\"\"\n",
    "    # Construct a textual summary of the scores to pass as context.\n",
    "    scores_text = \", \".join([f\"{emo}: {emotion_scores[f'{emo}_Score']:.2f}\" \n",
    "                             for emo in emotion_labels])\n",
    "    \n",
    "    # Constant context remains unchanged.\n",
    "    context = (\n",
    "        \"Key Excerpts from the Paper:\\n\"\n",
    "        \"1. Emotional flexibility is defined as the ability to adapt or regulate emotional responses based on context.\\n\"\n",
    "        \"2. It involves suppressing or expressing emotions according to changing situations.\\n\"\n",
    "        \"3. The concept includes core components such as context-sensitivity, behavioral repertoire, and responsiveness to feedback.\\n\"\n",
    "        \"4. The dynamic nature of emotional responses is crucial, indicating transitions over time rather than static states.\"\n",
    "    )\n",
    "    \n",
    "    # Combine the constant context with the variable prompt.\n",
    "    full_prompt = (\n",
    "        f\"Below are some key excerpts from a research paper on emotional flexibility:\\n{context}\\n\\n\"\n",
    "        f\"Using the following emotion scores: {scores_text}\\n\"\n",
    "        f\"{prompt_text}\"\n",
    "    )\n",
    "    \n",
    "    client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant focusing on emotion transitions.\"},\n",
    "            {\"role\": \"user\", \"content\": full_prompt},\n",
    "        ],\n",
    "        max_tokens=50,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_236180/1068203602.py:68: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Neutral' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_subset.loc[idx, 'Predicted_Emotion'] = scores_dict['Predicted_Emotion']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /home/jecroisp/Thesis/data/processed_data/p_crema/final_results_subset.csv\n",
      "Long-format results saved to /home/jecroisp/Thesis/data/processed_data/p_crema/final_results_long.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load CSV and Prepare df_subset\n",
    "# ---------------------------\n",
    "csv_file = \"/home/jecroisp/Thesis/data/processed_data/p_crema/GIF_Annotations.csv\"\n",
    "gif_folder = \"/home/jecroisp/Thesis/data/processed_data/p_crema/CremaGifs\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Create a new DataFrame with only the 'fileName' column.\n",
    "df_subset = df[['fileName']].copy()\n",
    "\n",
    "# Create the 'GIF_Path' column for processing.\n",
    "df_subset['GIF_Path'] = df_subset['fileName'].apply(lambda x: os.path.join(gif_folder, f\"{x}.gif\"))\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Initialize New Columns for Emotion Scores and GPT Captions\n",
    "# ---------------------------\n",
    "new_columns = [\n",
    "    'Predicted_Emotion', 'Anger_Score', 'Disgust_Score', 'Fear_Score',\n",
    "    'Happiness_Score', 'Neutral_Score', 'Sadness_Score', 'Max_Confidence'\n",
    "]\n",
    "# Add these columns with numerical default 0.0\n",
    "for col in new_columns:\n",
    "    df_subset[col] = 0.0\n",
    "\n",
    "# We'll have five separate GPT caption columns.\n",
    "for i in range(1, 6):\n",
    "    df_subset[f'GPT_Caption_{i}'] = \"\"\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Define Prompt Strings and Limit Processing Subset\n",
    "# ---------------------------\n",
    "prompts = [\n",
    "    \"Describe the emotional transition in the given scene with clarity, focusing solely on inferences drawn from the model's confidence scores. Interpret subtle differences between scores to determine when and how the subject's emotion shifts, using specific language (e.g., 'subject transitions from excitement to sadness') without mentioning direct numerical values or static labels. Keep the description concise (under 15 words) and ensure it captures the temporal progression of the scene.\",\n",
    "    \"Using only the variations in the confidence scores provided, succinctly articulate the subject's emotional shift over time. Capture the change from one dominant emotion to another using precise, dynamic verbs (e.g., 'morphs from surprise to calm') without quoting numbers. Limit your response to under 15 words.\",\n",
    "    \"Based solely on the model’s confidence score fluctuations, craft a brief narrative describing how the subject’s emotion evolves throughout the scene. Use specific phrases (e.g., 'switches from joy to apprehension') and avoid direct numerical references, keeping your description under 15 words.\",\n",
    "    \"Analyze the temporal trends in the emotion confidence scores to derive a succinct, natural language depiction of the subject's emotional transition. Employ clear descriptors (e.g., 'changes from elation to concern') without referencing exact figures, and keep it under 15 words.\",\n",
    "    \"Interpret the progression of emotion in the scene exclusively from the provided confidence scores. Deliver a concise (under 15 words) depiction of the shift using specific language (e.g., 'evolves from optimism to melancholy'), avoiding any direct numerical or static label mentions.\"\n",
    "]\n",
    "\n",
    "# Process only a subset (e.g., first 1125 GIFs)\n",
    "n_gifs = 1125\n",
    "df_subset = df_subset.iloc[:n_gifs].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Process Each GIF: Predict Scores and Generate Captions for All Prompts\n",
    "# ---------------------------\n",
    "for idx in range(len(df_subset)):\n",
    "    gif_path = df_subset.loc[idx, 'GIF_Path']\n",
    "    \n",
    "    # Load GIF frames as a tensor\n",
    "    gif_tensor = load_gif_as_tensor(gif_path)\n",
    "    if gif_tensor is None:\n",
    "        for i in range(1, 6):\n",
    "            df_subset.loc[idx, f'GPT_Caption_{i}'] = \"Error reading GIF.\"\n",
    "        continue\n",
    "    \n",
    "    # Predict emotion scores using the FER-VIT model.\n",
    "    scores_dict = predict_emotions_for_gif(model, gif_tensor)\n",
    "    if scores_dict is None:\n",
    "        for i in range(1, 6):\n",
    "            df_subset.loc[idx, f'GPT_Caption_{i}'] = \"Prediction failed.\"\n",
    "        continue\n",
    "    \n",
    "    # Update the DataFrame with the predicted scores.\n",
    "    df_subset.loc[idx, 'Predicted_Emotion'] = scores_dict['Predicted_Emotion']\n",
    "    df_subset.loc[idx, 'Anger_Score']     = scores_dict['Anger_Score']\n",
    "    df_subset.loc[idx, 'Disgust_Score']    = scores_dict['Disgust_Score']\n",
    "    df_subset.loc[idx, 'Fear_Score']       = scores_dict['Fear_Score']\n",
    "    df_subset.loc[idx, 'Happiness_Score']  = scores_dict['Happiness_Score']\n",
    "    df_subset.loc[idx, 'Neutral_Score']    = scores_dict['Neutral_Score']\n",
    "    df_subset.loc[idx, 'Sadness_Score']    = scores_dict['Sadness_Score']\n",
    "    df_subset.loc[idx, 'Max_Confidence']   = scores_dict['Max_Confidence']\n",
    "    \n",
    "    # For each prompt, generate a caption and store it in a separate column.\n",
    "    for i, prompt in enumerate(prompts, start=1):\n",
    "        caption = generate_caption_from_scores(scores_dict, prompt)\n",
    "        df_subset.loc[idx, f'GPT_Caption_{i}'] = caption\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Create Final DataFrame with Only 'fileName' and New Columns\n",
    "# ---------------------------\n",
    "final_columns = ['fileName'] + new_columns + [f'GPT_Caption_{i}' for i in range(1, 6)]\n",
    "df_final = df_subset[final_columns].copy()\n",
    "\n",
    "# Save the final DataFrame to a CSV file.\n",
    "output_csv = \"/home/jecroisp/Thesis/data/processed_data/p_crema/final_results_subset.csv\"\n",
    "df_final.to_csv(output_csv, index=False)\n",
    "print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Create a Separate Long-Format DataFrame for Prompts and Captions\n",
    "# ---------------------------\n",
    "# This DataFrame will have one row per GIF per prompt, with columns: fileName, Prompt_Text, GPT_Caption.\n",
    "rows = []\n",
    "for idx, row in df_final.iterrows():\n",
    "    file_name = row['fileName']\n",
    "    for i, prompt in enumerate(prompts, start=1):\n",
    "        rows.append({\n",
    "            \"fileName\": file_name,\n",
    "            \"Prompt_Text\": prompt,\n",
    "            \"GPT_Caption\": row[f'GPT_Caption_{i}']\n",
    "        })\n",
    "\n",
    "df_long = pd.DataFrame(rows)\n",
    "\n",
    "# Save the long-format DataFrame to a CSV file.\n",
    "output_long_csv = \"/home/jecroisp/Thesis/data/processed_data/p_crema/final_results_long.csv\"\n",
    "df_long.to_csv(output_long_csv, index=False)\n",
    "print(f\"Long-format results saved to {output_long_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>Predicted_Emotion</th>\n",
       "      <th>Anger_Score</th>\n",
       "      <th>Disgust_Score</th>\n",
       "      <th>Fear_Score</th>\n",
       "      <th>Happiness_Score</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>Sadness_Score</th>\n",
       "      <th>Max_Confidence</th>\n",
       "      <th>GPT_Caption_1</th>\n",
       "      <th>GPT_Caption_2</th>\n",
       "      <th>GPT_Caption_3</th>\n",
       "      <th>GPT_Caption_4</th>\n",
       "      <th>GPT_Caption_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_IEO_NEU_XX</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>0.015548</td>\n",
       "      <td>0.96109</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.96109</td>\n",
       "      <td>Subject transitions from neutral to a hint of ...</td>\n",
       "      <td>Shifts from neutrality to slight happiness, in...</td>\n",
       "      <td>The subject experiences shifts in emotional re...</td>\n",
       "      <td>The emotional journey shifts subtly from neutr...</td>\n",
       "      <td>Transitioning from calm neutrality, a subtle h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fileName Predicted_Emotion  Anger_Score  Disgust_Score  Fear_Score  \\\n",
       "0  1001_IEO_NEU_XX           Neutral     0.006635       0.002801    0.012297   \n",
       "\n",
       "   Happiness_Score  Neutral_Score  Sadness_Score  Max_Confidence  \\\n",
       "0         0.015548        0.96109       0.001629         0.96109   \n",
       "\n",
       "                                       GPT_Caption_1  \\\n",
       "0  Subject transitions from neutral to a hint of ...   \n",
       "\n",
       "                                       GPT_Caption_2  \\\n",
       "0  Shifts from neutrality to slight happiness, in...   \n",
       "\n",
       "                                       GPT_Caption_3  \\\n",
       "0  The subject experiences shifts in emotional re...   \n",
       "\n",
       "                                       GPT_Caption_4  \\\n",
       "0  The emotional journey shifts subtly from neutr...   \n",
       "\n",
       "                                       GPT_Caption_5  \n",
       "0  Transitioning from calm neutrality, a subtle h...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF: 1001_IEO_SAD_MD\n",
      "\n",
      "Predicted_Emotion: Neutral\n",
      "\n",
      "Max_Confidence: 0.7600553035736084\n",
      "\n",
      "Anger_Score: 0.10586223006248474\n",
      "\n",
      "Disgust_Score: 0.018845805898308754\n",
      "\n",
      "Fear_Score: 0.07468371838331223\n",
      "\n",
      "Happiness_Score: 0.04034707695245743\n",
      "\n",
      "Neutral_Score: 0.7600553035736084\n",
      "\n",
      "Sadness_Score: 0.00020592493820004165\n",
      "\n",
      "Generated Caption: Subject transitions from neutrality to a slight hint of fear with subtle fluctuations.\n",
      "\n",
      "GIF: 1001_IEO_SAD_MD\n",
      "\n",
      "Predicted_Emotion: Neutral\n",
      "\n",
      "Max_Confidence: 0.7600553035736084\n",
      "\n",
      "Anger_Score: 0.10586223006248474\n",
      "\n",
      "Disgust_Score: 0.018845805898308754\n",
      "\n",
      "Fear_Score: 0.07468371838331223\n",
      "\n",
      "Happiness_Score: 0.04034707695245743\n",
      "\n",
      "Neutral_Score: 0.7600553035736084\n",
      "\n",
      "Sadness_Score: 0.00020592493820004165\n",
      "\n",
      "Generated Caption: Subject transitions from neutrality to a slight hint of fear with subtle fluctuations.\n",
      "\n",
      "GIF: 1001_IEO_SAD_MD\n",
      "\n",
      "Predicted_Emotion: Neutral\n",
      "\n",
      "Max_Confidence: 0.7600553035736084\n",
      "\n",
      "Anger_Score: 0.10586223006248474\n",
      "\n",
      "Disgust_Score: 0.018845805898308754\n",
      "\n",
      "Fear_Score: 0.07468371838331223\n",
      "\n",
      "Happiness_Score: 0.04034707695245743\n",
      "\n",
      "Neutral_Score: 0.7600553035736084\n",
      "\n",
      "Sadness_Score: 0.00020592493820004165\n",
      "\n",
      "Generated Caption: Subject transitions from neutrality to a slight hint of fear with subtle fluctuations.\n",
      "\n",
      "GIF: 1001_IEO_SAD_MD\n",
      "\n",
      "Predicted_Emotion: Neutral\n",
      "\n",
      "Max_Confidence: 0.7600553035736084\n",
      "\n",
      "Anger_Score: 0.10586223006248474\n",
      "\n",
      "Disgust_Score: 0.018845805898308754\n",
      "\n",
      "Fear_Score: 0.07468371838331223\n",
      "\n",
      "Happiness_Score: 0.04034707695245743\n",
      "\n",
      "Neutral_Score: 0.7600553035736084\n",
      "\n",
      "Sadness_Score: 0.00020592493820004165\n",
      "\n",
      "Generated Caption: Subject transitions from neutrality to a slight hint of fear with subtle fluctuations.\n",
      "\n",
      "GIF: 1001_IEO_SAD_MD\n",
      "\n",
      "Predicted_Emotion: Neutral\n",
      "\n",
      "Max_Confidence: 0.7600553035736084\n",
      "\n",
      "Anger_Score: 0.10586223006248474\n",
      "\n",
      "Disgust_Score: 0.018845805898308754\n",
      "\n",
      "Fear_Score: 0.07468371838331223\n",
      "\n",
      "Happiness_Score: 0.04034707695245743\n",
      "\n",
      "Neutral_Score: 0.7600553035736084\n",
      "\n",
      "Sadness_Score: 0.00020592493820004165\n",
      "\n",
      "Generated Caption: Subject transitions from neutrality to a slight hint of fear with subtle fluctuations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1,6):\n",
    "    print('GIF: ' + df_final['fileName'].iloc[i] + '\\n')\n",
    "    print('Predicted_Emotion: ' + df_final['Predicted_Emotion'].iloc[i] + '\\n')\n",
    "    print('Max_Confidence: ' + df_final['Max_Confidence'].iloc[i].astype(str) + '\\n')\n",
    "    print('Anger_Score: ' + df_final['Anger_Score'].iloc[i].astype(str) + '\\n')\n",
    "    print('Disgust_Score: ' + df_final['Disgust_Score'].iloc[i].astype(str) + '\\n')\n",
    "    print('Fear_Score: ' + df_final['Fear_Score'].iloc[i].astype(str) + '\\n')\n",
    "    print('Happiness_Score: ' + df_final['Happiness_Score'].iloc[i].astype(str) + '\\n')\n",
    "    print('Neutral_Score: ' + df_final['Neutral_Score'].iloc[i].astype(str) + '\\n')\n",
    "    print('Sadness_Score: ' + df_final['Sadness_Score'].iloc[i].astype(str) + '\\n')\n",
    "    print('Generated Caption: ' + df_final['GPT_Caption_1'].iloc[i] + '\\n')\n",
    "# print(df_final['GPT_Caption_2'].iloc[0] + '\\n')\n",
    "# print(df_final['GPT_Caption_3'].iloc[0] + '\\n')\n",
    "# print(df_final['GPT_Caption_4'].iloc[0] + '\\n')\n",
    "# print(df_final['GPT_Caption_5'].iloc[0] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
